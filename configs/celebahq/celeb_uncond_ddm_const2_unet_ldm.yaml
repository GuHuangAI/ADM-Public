model:
  class_name: ddm.ddm_const_2.LatentDiffusion
  image_size: [256, 256]
  ckpt_path:
  ignore_keys: []
  only_model: False
  sampling_timesteps: 10
  loss_type: l2
  start_dist: normal
  perceptual_weight: 1
  scale_factor: 0.165
  scale_by_std: True
  default_scale: True
  scale_by_softsign: False
  eps: !!float 1e-3
  sigma_max: 1
  sigma_min: 0.001
  ldm: True
  weighting_loss: False
  use_disloss: False
  use_l1: False
  use_augment: False
  first_stage:
    class_name: ddm.encoder_decoder.AutoencoderKL
    embed_dim: 3
    lossconfig:
      disc_start: 20001
      kl_weight: 0.000001
      disc_weight: 0.5
    ddconfig:
      double_z: True
      z_channels: 3
      resolution: [ 256, 256 ]
      in_channels: 3
      out_ch: 3
      ch: 128
      ch_mult: [ 1,2,4 ]  # num_down = len(ch_mult)-1
      num_res_blocks: 2
      attn_resolutions: [ ]
      dropout: 0.0
    ckpt_path: "/data/huang/celebahq/results_ae_kl_256x256_d4/model-10.pt"
  unet:
    class_name: unet.uncond_unet_sd_2.EDMPrecond
    img_resolution: 64
    img_channels: 3
    sigma_data: 1.0  # Expected standard deviation of the training data.
    model_type: 'DhariwalUNet'
    model_channels: 128  # Base multiplier for the number of channels.
    channel_mult: [ 1, 2, 2, 2 ]
    channel_mult_emb: 4  # Multiplier for the dimensionality of the embedding vector.
    num_blocks: 3  # Number of residual blocks per resolution.
    attn_resolutions: [ 16, 8 ]  # List of resolutions with self-attention.
    dropout: 0.  # dropout.
    label_dropout: 0
    augment_dim: 0

data:
  class_name: ddm.data.ImageDataset
  image_size: [256, 256]
  img_folder: "/data/huang/celebahq/celeba_hq_256/"
  augment_horizontal_flip: True
  batch_size: 64
  num_workers: 4

eval:
  begin_ckpt: 1
  end_ckpt: 35
  num_samples: 30000
  batch_size: 64
  use_ema: True
  workdir: "/data/huang/celebahq/results_ddm_const2_ldm_uncond_unet"
#  gt_stats: "/nfs/data/diffusion_data/cifar/cifar10/results_etp_const_sde4_ncsnpp6/gt_feature.pth"
  gt_stats:

trainer:
  gradient_accumulate_every: 4
  lr: !!float 1e-4
  min_lr: !!float 1e-5
  train_num_steps: 400000
  save_and_sample_every: 10000
  log_freq: 500
  results_folder: "/data/huang/celebahq/results_ddm_const2_ldm_uncond_unet"
  amp: False
  fp16: False
  resume_milestone: 0
  test_before: True
  ema_update_after_step: 20000
  ema_update_every: 2

sampler:
  batch_size: 32
  out_channels: 3
  sample_num: 30000
  use_ema: True
  test_in_train: False
  ckpt_path: "/data/huang/celebahq/results_ddm_const_ldm_uncond_unet/model-21.pt"
  save_folder: "/data/huang/celebahq/results_ddm_const_ldm_uncond_unet/samples_model-21-step10"
  target_path: "/data/huang/celebahq/celeba_hq_256"