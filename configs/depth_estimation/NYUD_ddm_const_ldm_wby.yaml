model:
  class_name: ddm.ddm_const3.LatentDiffusion
  image_size: [320, 320]
  ckpt_path:
  ignore_keys: []
  only_model: False
  sampling_timesteps: 10
  loss_type: l2
  start_dist: normal
  perceptual_weight: 0
  scale_factor: 0.3
  scale_by_std: True
  default_scale: True
  scale_by_softsign: False
  eps: !!float 1e-4
  sigma_max: 1
  sigma_min: 0.01
  ldm: True
  weighting_loss: True
  use_disloss: True
  use_l1: False
  use_augment: False
  loss_main:
    class_name: ddm.loss.MEADSTD_TANH_NORM_Loss
    valid_threshold: 0.001
    max_threshold: 1
    with_sigmoid: True
  loss_vlb:
    class_name: ddm.loss.MAE_Loss
    thresh_min: 0.001
    thresh_max: 1
    mask: True
    with_sigmoid: True
  loss_dis:
    class_name: ddm.loss.MAE_Loss
    thresh_min: 0.0001
    thresh_max: 1
    mask: True
  first_stage:
    class_name: ddm.encoder_decoder.AutoencoderKL
    embed_dim: 3
    lossconfig:
      disc_start: 50001
      kl_weight: 0.000001
      disc_weight: 0.5
      disc_in_channels: 1
    ddconfig:
      double_z: True
      z_channels: 3
      resolution: [ 320, 320 ]
      in_channels: 1
      out_ch: 1
      ch: 128
      ch_mult: [ 1,2,4 ]  # num_down = len(ch_mult)-1
      num_res_blocks: 2
      attn_resolutions: [ ]
      dropout: 0.0
    ckpt_path: "/data/run01/scv2060/wby/NYUDv2/result/model-10.pt"
  unet:
    class_name: unet.cond_unet3.Unet
    fix_bb: False
    cond_net: swin
    dim: 128
    channels: 3
    out_mul: 1
    dim_mults: [ 1, 2, 4, 4] # num_down = len(dim_mults)
    cond_in_dim: 3
    cond_dim: 128
    cond_dim_mults: [ ] # num_down = len(cond_dim_mults)
    window_sizes1: [ [ 8, 8 ], [ 4, 4 ], [ 2, 2 ], [ 1, 1 ] ]
    window_sizes2: [ [ 8, 8 ], [ 4, 4 ], [ 2, 2 ], [ 1, 1 ] ]
    fourier_scale: 16
    cond_pe: False
    num_pos_feats: 128
    cond_feature_size: [ 128, 128 ]
#    ckpt_path: "/nfs/data/pretrain_weight/cifar10_ncsnpp_deep_continuous.pth"

data:
  class_name: ddm.data.NYUDv2DepthDataset
  image_size: [320, 320]
  data_root: '/data/run01/scv2060/wby/NYUDv2/official_split'
  split: 'train'
  augment_horizontal_flip: True
  batch_size: 8

eval:
  begin_ckpt: 1
  end_ckpt: 35
  num_samples: 50000
  batch_size: 64
  use_ema: True
  workdir: "/data/huang/cifar-10-python/results_ddm_const"
#  gt_stats: "/nfs/data/diffusion_data/cifar/cifar10/results_etp_const_sde4_ncsnpp6/gt_feature.pth"
  gt_stats:

trainer:
  gradient_accumulate_every: 2
  lr: !!float 5e-5
  min_lr: !!float 5e-6
  train_num_steps: 300000
  save_and_sample_every: 10000
  log_freq: 500
  results_folder: "/data/run01/scv2060/wby/NYUDv2/stage2"
#  results_folder: "/data/huang/cifar-10-python/results_etp_const_sde4_ncsnpp10"
  amp: False
  fp16: False
  resume_milestone: 0
  test_before: True
  ema_update_after_step: 20000
  ema_update_every: 8

sampler:
  batch_size: 128
  sample_num: 50000
  use_ema: True
  test_in_train: False
  ckpt_path: "/data/huang/cifar-10-python/results_etp_const_sde4_ncsnpp10/model-80.pt"
  save_folder: "/data/huang/cifar-10-python/sample_etp_const_sde4_ncsnpp10"
  target_path: "/data/huang/cifar-10-python/cifar-10-train-png"